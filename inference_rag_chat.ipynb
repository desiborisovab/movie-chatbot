{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7493fdc1-4c63-412c-bd2a-5222afaa0826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "54c0762a-1828-47a6-9ce1-236c7fec25ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31bb1d2b-74a3-4b89-a649-76e1630a2a87",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from pyspark.sql import functions as F\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "RUN_ID = \"fe9ecda0ef3d49d0ae5b96847f975de9\"\n",
    "\n",
    "# Load model from MLflow\n",
    "lm_model = mlflow.tensorflow.load_model(f\"runs:/{RUN_ID}/model\")\n",
    "\n",
    "# Load vocab from MLflow artifact\n",
    "vocab = json.loads(mlflow.artifacts.load_text(f\"runs:/{RUN_ID}/vocab.json\"))\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    max_tokens=len(vocab),\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    output_mode=\"int\",\n",
    ")\n",
    "vectorizer.set_vocabulary(vocab)\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "params = client.get_run(RUN_ID).data.params\n",
    "SEQ_LEN = int(params[\"SEQ_LEN\"])\n",
    "print(\"SEQ_LEN:\", SEQ_LEN)\n",
    "\n",
    "id_to_token = np.array(vocab)\n",
    "\n",
    "print(\"Loaded model. vocab_size =\", VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de12ab5f-df8b-4424-bad9-0a37c926b61f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sample_from_logits(logits, temperature=0.8, top_k=50):\n",
    "    # logits: shape (vocab_size,)\n",
    "    logits = tf.cast(logits, tf.float32)\n",
    "    logits = logits / max(float(temperature), 1e-6)\n",
    "\n",
    "    if top_k is not None and top_k > 0:\n",
    "        values, _ = tf.math.top_k(logits, k=min(int(top_k), logits.shape[-1]))\n",
    "        cutoff = values[-1]\n",
    "        logits = tf.where(logits < cutoff, tf.constant(-1e10, logits.dtype), logits)\n",
    "\n",
    "    probs = tf.nn.softmax(logits)\n",
    "    next_id = int(tf.random.categorical(tf.math.log([probs]), 1)[0, 0])\n",
    "    return next_id\n",
    "\n",
    "def detokenize(ids):\n",
    "    toks = id_to_token[ids]\n",
    "    toks = [t for t in toks if t not in (\"\", \"[UNK]\")]\n",
    "    return \" \".join(toks)\n",
    "\n",
    "def generate(prompt, max_new_tokens=120, temperature=0.7, top_k=50):\n",
    "    # vectorizer returns padded ids; we drop zeros\n",
    "    ids = vectorizer(tf.constant([prompt]))[0]\n",
    "    ids = tf.boolean_mask(ids, ids > 0).numpy().tolist()\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        window = ids[-SEQ_LEN:]\n",
    "        if len(window) < SEQ_LEN:\n",
    "            window = [0] * (SEQ_LEN - len(window)) + window\n",
    "\n",
    "        x = tf.constant([window], dtype=tf.int32)\n",
    "        logits = lm_model(x)  # (1, SEQ_LEN, vocab)\n",
    "        next_id = sample_from_logits(logits[0, -1], temperature=temperature, top_k=top_k)\n",
    "        ids.append(next_id)\n",
    "\n",
    "    return detokenize(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4a4bb1f-09d9-427a-9060-1987ccd38297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MOVIE_TABLE = \"default.wiki_movie_plots_deduped\"\n",
    "\n",
    "def retrieve_movies(question: str, k: int = 5):\n",
    "    q = (question or \"\").lower().strip()\n",
    "    tokens = [t for t in re.findall(r\"[a-z0-9]+\", q) if len(t) >= 3]\n",
    "    tokens = list(dict.fromkeys(tokens))  # unique, preserve order\n",
    "\n",
    "    df = spark.table(MOVIE_TABLE)\n",
    "\n",
    "    # Create a \"haystack\" field for simple keyword contains checks\n",
    "    hay = F.lower(F.concat_ws(\" \",\n",
    "        F.coalesce(F.col(\"Title\"), F.lit(\"\")),\n",
    "        F.coalesce(F.col(\"Plot\"), F.lit(\"\")),\n",
    "        F.coalesce(F.col(\"Genre\"), F.lit(\"\")),\n",
    "        F.coalesce(F.col(\"Director\"), F.lit(\"\")),\n",
    "        F.coalesce(F.col(\"Cast\"), F.lit(\"\"))\n",
    "    ))\n",
    "\n",
    "    if not tokens:\n",
    "        # fallback: just return some rows\n",
    "        return df.limit(k)\n",
    "\n",
    "    score = None\n",
    "    for t in tokens:\n",
    "        hit = F.when(hay.contains(t), F.lit(1)).otherwise(F.lit(0))\n",
    "        score = hit if score is None else (score + hit)\n",
    "\n",
    "    return (df\n",
    "            .withColumn(\"_score\", score)\n",
    "            .where(F.col(\"_score\") > 0)\n",
    "            .orderBy(F.col(\"_score\").desc())\n",
    "            .limit(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23e85005-2fee-4edd-9e9e-419727e6d7e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def format_context(rows, max_plot_chars=500):\n",
    "    blocks = []\n",
    "    for r in rows:\n",
    "        title = (r[\"Title\"] or \"\").strip()\n",
    "        year  = r[\"Release Year\"]\n",
    "        genre = (r[\"Genre\"] or \"\").strip()\n",
    "        director = (r[\"Director\"] or \"\").strip()\n",
    "        cast = (r[\"Cast\"] or \"\").strip()\n",
    "        plot = (r[\"Plot\"] or \"\").strip()\n",
    "\n",
    "        if len(plot) > max_plot_chars:\n",
    "            plot = plot[:max_plot_chars].rsplit(\" \", 1)[0] + \"...\"\n",
    "\n",
    "        blocks.append(\n",
    "            f\"Title: {title}\\n\"\n",
    "            f\"Year: {year}\\n\"\n",
    "            f\"Genre: {genre}\\n\"\n",
    "            f\"Director: {director}\\n\"\n",
    "            f\"Cast: {cast}\\n\"\n",
    "            f\"Plot: {plot}\\n\"\n",
    "        )\n",
    "    return \"\\n---\\n\".join(blocks).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04c173c3-255a-4ead-a8e6-8743b8fda660",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def answer(question: str, k: int = 5,\n",
    "           max_new_tokens: int = 120,\n",
    "           temperature: float = 0.7,\n",
    "           top_k: int = 50):\n",
    "\n",
    "    rows = retrieve_movies(question, k=k).collect()\n",
    "    context = format_context(rows)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a movie assistant.\\n\"\n",
    "        \"Use only the CONTEXT to answer. If the answer is not in the context, say \\\"I don't know.\\\"\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context}\\n\\n\"\n",
    "        f\"QUESTION:\\n{question}\\n\\n\"\n",
    "        \"ANSWER:\\n\"\n",
    "    )\n",
    "\n",
    "    return generate(prompt, max_new_tokens=max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "\n",
    "test_rows = retrieve_movies(\"Kansas Saloon Smashers\", k=3).collect()\n",
    "print(\"Retrieved rows:\", len(test_rows))\n",
    "print(\"First title:\", test_rows[0][\"Title\"] if test_rows else \"NONE\")\n",
    "\n",
    "q = \"Tell me about Kansas Saloon Smashers.\"\n",
    "resp = answer(q, k=5, max_new_tokens=120, temperature=0.7, top_k=50)\n",
    "print(resp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "inference_rag_chat",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
